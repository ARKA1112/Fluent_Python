{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'caf\\xc3\\xa9'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ENcoding = an algorith that converts code points to vyte sequences and vice versa\n",
    "\n",
    "\n",
    "#Converting to bytes from code is encoding and vice versa is decoding\n",
    "\n",
    "\n",
    "s = 'café'\n",
    "len(s)\n",
    "b = s.encode('utf8')\n",
    "print(b) #the code point for “é” is encoded as two bytes in UTF-8\n",
    "len(b)   #that is why lenght is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Byte Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'a', 'f', 'Ã', '©']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A five-byte sequence as bytes and as bytearray\n",
    "\n",
    "cafe = bytes('café',encoding='utf-8')\n",
    "I = [cafe[i] for i in range(len(cafe))]\n",
    "#each of the integers are the bytes\n",
    "#if we tyr\n",
    "[chr(i) for i in I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1K\\xce\\xa9'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can convert i to array also\n",
    "\n",
    "cafe_arr = bytearray(cafe)\n",
    "cafe_arr[0]\n",
    "bytes.fromhex('31 4B CE A9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiating bytes from the raw data of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import array\n",
    "numbers = array.array('h',[-2,-1,0,1,2])\n",
    "octets = bytes(numbers)\n",
    "octets.hex()\n",
    "octets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"array('h', [-2, -1, 0, 1, 2])\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The String \"El Nino\" encoded with three codecs producing very different byte sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin_1\n",
      "b'El Nino'\n",
      "utf_8\n",
      "b'El Nino'\n",
      "utf_16\n",
      "b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00n\\x00o\\x00'\n"
     ]
    }
   ],
   "source": [
    "for codec in ['latin_1', 'utf_8', 'utf_16']:\n",
    "    print(codec, 'El Nino'.encode(codec), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A\\x00'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A ='A'\n",
    "B = bytes(A.encode('utf-16le'))\n",
    "B.decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Encode/Decode Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'So Paulo'\n",
      "b'S?o Paulo'\n",
      "b'S&#227;o Paulo'\n"
     ]
    }
   ],
   "source": [
    "#Two types of error\n",
    "#unicodedecodeerror\n",
    "#unicodeencodeerror\n",
    "\n",
    "city = 'São Paulo'\n",
    "city.encode('utf_8')\n",
    "city.encode('utf_16')\n",
    "#city.encode('cp437')   #fails as it cant handle ã\n",
    "print(city.encode('cp437', errors='ignore'))\n",
    "print(city.encode('cp437',errors='replace'))\n",
    "print(city.encode('cp437', errors='xmlcharrefreplace')) ##If you cant use utf use xmlcharrefreplace instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montréal\n",
      "MontrИal\n",
      "Montr�al\n"
     ]
    }
   ],
   "source": [
    "#Decoding from str to bytes: success and error handling\n",
    "\n",
    "octets  = b'Montr\\xe9al'  #in latin1\n",
    "for i in [octets.decode('cp1252'),octets.decode('koi8_r'),octets.decode('utf_8',errors='replace')]:\n",
    "    print(i)\n",
    "\n",
    "#The xe9 or é equates to no code in utf_8 hence the replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00E\\x00l\\x00 \\x00N\\x00i\\x00n\\x00o'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 110, 0, 111]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How to detect the encodings\n",
    "#utf_16le is little encoding utf_16be is big encoding\n",
    "#only way to detect is if we have that info\n",
    "u16 = 'El Nino'.encode('utf_16be')\n",
    "print(u16)   #the \\xff\\xfeE is called byte order remark denoting the little endian byte ordering of the intel cpu where the encoding was performed\n",
    "list(u16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c5086-1c37-4a8a-a418-a5a2e7119b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open('cafe.txt','w',encoding='utf-16be').write('café')\n",
    "#encoding fromat must be specified while writing a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac82690-6fcd-422c-9550-635900d47223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open('cafe.txt', encoding='utf-16be').read()\n",
    "#encoding must also be specified while reading the file also\n",
    "#thus eliminates the problem of misreading the encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b86d6-9f5e-4ae0-9f88-af012277b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cafe.txt', 'w', encoding='utf_8') as fp:\n",
    "    fp.write('café')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda779e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9e6f8-24a9-430e-b76e-0d0a6871edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92234515-83d1-4700-a962-015142263a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.stat('cafe.txt').st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ae5db-93d4-4f60-bbeb-4849727a2a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp2 = open('cafe.txt')\n",
    "fp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53e89c-8c41-4784-8b97-fabb0b346a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp2.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc55f8-b50e-41e0-aeec-fd77a5ae91ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34589d7d-4133-44e4-bd5c-84552289a07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafÃ©'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#also can do the following\n",
    "fp2 = open('cafe.txt', encoding='cp1252')\n",
    "fp2.read() #because encoding is in cp1252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ea52b-c178-42d0-a3d0-22ef73f264c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='utf_8'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp3 = open('cafe.txt', encoding='utf_8')\n",
    "fp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71eb69-631b-42cf-aa3a-6a477e7a9a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp3.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4b6ec-343b-4d8e-bfb0-67bdd30a170b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp4 = open('cafe.txt','rb')\n",
    "fp4.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49c11d-e49f-445c-87d8-81fa77fffc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() - > 'UTF-8'\n",
      "                 type(my_file) - > <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding - > 'UTF-8'\n",
      "           sys.stdout.isatty() - > False\n",
      "           sys.stdout.encoding - > 'UTF-8'\n",
      "            sys.stdin.isatty() - > False\n",
      "            sys.stdin.encoding - > 'utf-8'\n",
      "           sys.stderr.isatty() - > False\n",
      "           sys.stderr.encoding - > 'UTF-8'\n",
      "      sys.getdefaultencoding() - > 'utf-8'\n",
      "   sys.getfilesystemencoding() - > 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import locale\n",
    "\n",
    "expressions = \"\"\"\n",
    "        locale.getpreferredencoding()\n",
    "        type(my_file)\n",
    "        my_file.encoding\n",
    "        sys.stdout.isatty()\n",
    "        sys.stdout.encoding\n",
    "        sys.stdin.isatty()\n",
    "        sys.stdin.encoding\n",
    "        sys.stderr.isatty()\n",
    "        sys.stderr.encoding\n",
    "        sys.getdefaultencoding()\n",
    "        sys.getfilesystemencoding()\n",
    "    \"\"\"\n",
    "\n",
    "my_file = open('dummy','w')\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print(f'{expression:>30} - > {value!r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37828d-6044-4f9f-918d-a43e8b003360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]\n",
      "\n",
      "sys.stdout.isatty(): False\n",
      "sys.stdout.encoding: UTF-8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from unicodedata import name\n",
    "\n",
    "print(sys.version)\n",
    "print()\n",
    "print('sys.stdout.isatty():', sys.stdout.isatty())\n",
    "print('sys.stdout.encoding:', sys.stdout.encoding)\n",
    "print()\n",
    "\n",
    "test_chars = [\n",
    "    '\\N{HORIZONTAL ELLIPSIS}', #exists in cp1252 not in cp437\n",
    "    '\\N{INFINITY}', #exists in cp437 not in cp1252\n",
    "    '\\N{CIRCLED NUMBER FORTY TWO}'] #not in cp437 or in cp1252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0dbf70-8806-48cd-aec9-4f6e2c239739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to output HORIZONTAL ELLIPSIS:\n",
      "…\n",
      "Trying to output INFINITY:\n",
      "∞\n",
      "Trying to output CIRCLED NUMBER FORTY TWO:\n",
      "㊷\n"
     ]
    }
   ],
   "source": [
    "for chars in test_chars:\n",
    "    print(f'Trying to output {name(chars)}:')\n",
    "    print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4619e30-d714-4a82-92f5-2f61a3ff545b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicodedata import normalize,name\n",
    "ohm = '\\u2126'\n",
    "name(ohm)\n",
    "ohm #But this is also same as the Greek alphabet\n",
    "#omega \n",
    "#To normalize this we do the following\n",
    "\n",
    "ohm_c = normalize('NFC',ohm)\n",
    "name(ohm_c)\n",
    "\n",
    "ohm == ohm_c\n",
    "\n",
    "normalize('NFC', ohm) == normalize('NFC', ohm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro = '\\u00B5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'µ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name(micro)\n",
    "micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "½\n",
      "1\tDIGIT ONE\n",
      "⁄\tFRACTION SLASH\n",
      "2\tDIGIT TWO\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "\n",
    "half = '\\N{VULGAR FRACTION ONE HALF}'\n",
    "print(half)\n",
    "normalize('NFKC', half)\n",
    "\n",
    "\n",
    "for char in normalize('NFKC', half):\n",
    "    print(char, name(char), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[181, 956]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_squared = '4²'\n",
    "normalize('NFKC', four_squared)\n",
    "micro = 'µ'\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "micro, micro_kc\n",
    "name(micro), name(micro_kc)\n",
    "\n",
    "list(map(ord , (micro, micro_kc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = lambda x: ord(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap(micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simillar to like str.lower()\n",
    "#But it is used to lower the cases of different signs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions for Normalized Text Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#way to remove diatrics frm a string\n",
    "from unicodedata import normalize\n",
    "\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() == normalize('NFC', str2).casefold())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "def shave_marks(txt):\n",
    "    \"\"\"remove all diatrics marks\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = 'Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.'\n",
    "shave_marks(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sorting Unicode text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt_BR.UTF-8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted(fruits)  #sorts on basis of english utf-8\n",
    "\n",
    "#since the fruit names are in portugese \n",
    "#to do this\n",
    "#real sorting would have been ['açaí', 'acerola', 'atemoia', 'cajá', 'caju']\n",
    "\n",
    "import locale\n",
    "my_locale = locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')\n",
    "print(my_locale)\n",
    "\n",
    "sorted(fruits, key=locale.strxfrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `pyuca` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Unicode Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designing a character finding utility\n",
    "\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "START, END = ord(' '), sys.maxunicode + 1\n",
    "\n",
    "def find(*query_words, start=START, end=END):\n",
    "    query = {words.upper() for words in query_words}\n",
    "    for code in range(start, end):\n",
    "        char = chr(code)\n",
    "        name = unicodedata.name(char, None)\n",
    "        if name and query.issubset(name.split()):\n",
    "            print(f'U+{code:04X}\\t{char}\\t{name}')\n",
    "\n",
    "def main(words):\n",
    "    if words:\n",
    "        find(*words)\n",
    "    else:\n",
    "        print('pls provide the words to find')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('cafe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "#Demo of Unicode database numerical character metadata (callouts describe each column in the output)\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "re_digit = re.compile(r'\\d')\n",
    "\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "\n",
    "\n",
    "for char in sample:\n",
    "    print(f'U+{ord(char):04x}',\n",
    "    char.center(6),\n",
    "    're_dig' if re_digit.match(char) else '-',\n",
    "    'isdig' if char.isdigit() else '-',\n",
    "    'isnum' if char.isnumeric() else '-',\n",
    "    f'{unicodedata.numeric(char):5.2f}',\n",
    "    unicodedata.name(char),\n",
    "    sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str versus bytes in regular expressions\n",
    "\n",
    "\n",
    "import re\n",
    "re_numbers_str = re.compile(r'\\d+')\n",
    "re_words_str = re.compile(r'\\w+')\n",
    "re_numbers_bytes = re.compile(rb'\\d+')\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\"\"as 1729 = 1³ + 12³ = 9³ + 10³.\")\n",
    "\n",
    "text_bytes = text_str.encode('utf_8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      " 'Ramanujan saw ௧௭௨௯as 1729 = 1³ + 12³ = 9³ + 10³.'\n",
      "Numbers\n",
      "  str  : ['௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      "  bytes  : [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      "  str  : ['Ramanujan', 'saw', '௧௭௨௯as', '1729', '1³', '12³', '9³', '10³']\n",
      "  bytes: [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "print(f'Text\\n {text_str!r}')\n",
    "print('Numbers')\n",
    "print('  str  :', re_numbers_str.findall(text_str))\n",
    "print('  bytes  :', re_numbers_bytes.findall(text_bytes))\n",
    "print('Words')\n",
    "print('  str  :', re_words_str.findall(text_str))\n",
    "print('  bytes:', re_words_bytes.findall(text_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa46da6b9307ef350aad613908c1591a068b15a96db2be16e9d9e053b74e28ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
